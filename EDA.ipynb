{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Airbnb Listings**\n",
                "\n",
                "This project will analyse the dataset for Airbnb listing in Melbourne as of August 2022. We will investigate the most common areas, most popular hosts, and what factors may contribute to the price.\n",
                "\n",
                "**Contents:**\n",
                "1. Introduction\n",
                "2. Summary\n",
                "3. Data Wrangling\n",
                "4. Analysis\n",
                "5. Conclusion\n",
                "6. Recommendations\n",
                "7. References"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **1. Introduction**\n",
                "\n",
                "Since 2008, Airbnb has enabled homeowners to control when the want to rent out their home for short-term homestays. Seen as an easy way to profit on a home that may be vacant part of year it has become extremely popular.\n",
                "For this project we will analyse the current market in Melbourne, and extract insights such as what makes a home popular, what influences the prices, and where demand and supply may not be at equilibrium. \n",
                "\n",
                "Please note that due to size of this dataset (exceeding the 20mb limit) I have only updated part of it which may skew results.\n",
                "\n",
                "**Questions we will be answering:**\n",
                "\n",
                "* As of 2022, what is the most common suburb to find an Airbnb with over a 4 star rating? \n",
                "* As of 2022, what suburbs have the most bookings?\n",
                "* What is the distribution of prices for different suburbs?\n",
                "* Which hosts are the most popular, why?\n",
                "* Does the number of reviews have an effect on the price/Availability?\n",
                "* What are the common terms used in reviews for some of the most popular hosts?\n",
                "* Most common amenities in popular Airbnb's that are not available in the less common Airbnb's\n",
                "* Does being a super host contribute to more bookings?\n",
                "\n",
                "\n",
                "**Data Files**\n",
                "\n",
                "This notebook uses the 3 datasets below. The hosts and reviews tables are linked to the listings table through the host_id and listing_id, respectively. The data sets contain a lot of columns, so we will only explain a certain selection that by title may not make sense what data they contain.\n",
                "\n",
                "All file obtained from:  http://insideairbnb.com/get-the-data\n",
                "\n",
                "**listings.csv**\n",
                "* **Id**  (unique identifier)\n",
                "* **Accomodates** (how many people can fit in the house)\n",
                "* **Amenities** (a list of all the amenities included in the house)\n",
                "* **Minimum_nights** (the minimum nights someone can book for)\n",
                "* **Maximum_nights** (the maximum nights a person can book for)\n",
                "* **availabilty_30** (how many nights are available in the next 30 days)\n",
                "* **availablity_60** (how many nights are available in the next 60 days)\n",
                "* **availability_90** (how many nights are available in the next 90 days)\n",
                "* **availabilty_365** (how many nights are available in the next 365 days)\n",
                "* **Instant_bookable** (If the house can be booked without the host needing to approve)\n",
                "\n",
                "\n",
                "**hosts.csv**\n",
                "* **host_id** (Unique identifier)\n",
                "* **host_since** (how long the user has been a host)\n",
                "* **host_about** (the description about the host)\n",
                "* **host_acceptance_rate** (how often the host accepts request to rent their house)\n",
                "* **host_superhost** (Users are given this badge by meeting/exceeding guest expectations)\n",
                "* **host_total_listing_count** (how many listing the host has on Airbnb)\n",
                "\n",
                "**reviews.csv**\n",
                "* **Listing_id** (Foreign key, to link to listing table)\n",
                "* **Id** (Unique identifier)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **1. Summary**\n",
                "\n",
                "Overall, our findings showed that the listings on Airbnb are not well correlated with many of the attributes that we investigated. The biggest finding that could determine the pricing would be the area of the listing, areas further from the cbd seem to have higher pricing."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **2. Data Wrangling**\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import required libraries\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "import geopandas as gpd\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# read in data\n",
                "listings = pd.read_csv('data/listings.csv')\n",
                "hosts = pd.read_csv('data/hosts.csv')\n",
                "reviews = pd.read_csv('data/reviews.csv')\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Have a look at the data\n",
                "print(listings.columns)\n",
                "print(listings.shape)\n",
                "print(listings.dtypes)\n",
                "print(listings.count())\n",
                "print(listings[listings.duplicated()])\n",
                "listings.head()\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Most the data looks good. Columns are all loaded in and, correct amount of rows and no duplicates.\n",
                "\n",
                "Some fixes that we will do to clean the data include:\n",
                "* Remove the text from the bathrooms_text column so its only an float, making it easier to work with.\n",
                "* fix data types of some columns\n",
                "  * first_review\n",
                "  * last_review to date types\n",
                "* Rename neighbourhood_cleansed to just neighbourhood\n",
                "* Explore the null values, decide what to do with them.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using regex we can remove any letters '[A-Za-z]'.\n",
                "# leaving us only the number of bathrooms\n",
                "listings['bathrooms_text'] = listings['bathrooms_text'].str.replace(r'[A-Za-z]','')\n",
                "\n",
                "# remove any blank spaces from the strings\n",
                "listings['bathrooms_text'] = listings['bathrooms_text'].str.strip()\n",
                "\n",
                "# assuming a dash '-' means no bathrooms, we replace this with 0\n",
                "listings['bathrooms_text'] = listings['bathrooms_text'].str.replace('-', '0')\n",
                "\n",
                "# rename column to a more appropriate name\n",
                "listings.rename(columns = {'bathrooms_text':'bathrooms'}, inplace=True)\n",
                "\n",
                "# now we can change the data type to a float\n",
                "listings['bathrooms'] = listings['bathrooms'].astype('float')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# convert first_review and last_review to datetime type\n",
                "listings[\"last_review\"] = pd.to_datetime(listings[\"last_review\"], infer_datetime_format=True)\n",
                "listings[\"first_review\"] = pd.to_datetime(listings[\"first_review\"], infer_datetime_format=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# rename columns \n",
                "listings.rename(columns={'neighbourhood_cleansed':'neighbourhood'}, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We can focus on 30 day and 360 day availability and overall score rating.\n",
                "# filter out columns availability 60/90, and all review_scores except rating.\n",
                "unwanted_columns = ['availability_60', 'availability_90','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value']\n",
                "listings = listings.drop(columns=unwanted_columns)\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# How many null values do we Have\n",
                "listings.isna().sum()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the empty columns :\n",
                "* description is empty likely becaues the host has put any information there\n",
                "* review columns empty from not receiving any reviews yet\n",
                "* airbnb allows tents, single rooms and apartments that may be not have a seperate rooms for the bed so we may assume this the reason for null values in bathrooms/bedrooms/beds columns.\n",
                "\n",
                "We will set NA values in bathrooms bedrooms and beds to 0 instead of NaN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings[['bathrooms','bedrooms','beds']].fillna(0, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# final result of our cleaning.\n",
                "print(listings.info())\n",
                "listings.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings.describe()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**File 2:  host.csv**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inspect dataset\n",
                "\n",
                "display(hosts.shape)\n",
                "display(hosts[hosts.duplicated()])\n",
                "display(hosts.info())\n",
                "display(hosts.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "hosts.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Some fixes that we can do include:**\n",
                "\n",
                "* remove duplicate row.\n",
                "* remove unwanted columns.\n",
                "* Change data type of columns to something more appropriate.  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop duplicate entry\n",
                "hosts.drop_duplicates(inplace=True)\n",
                "# Drop unwanted columns \n",
                "unwanted_columns_hosts = ['host_listings_count', 'host_verifications', 'host_has_profile_pic']\n",
                "hosts.drop(columns=unwanted_columns_hosts, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# change to date type\n",
                "hosts['host_since'] = pd.to_datetime(hosts['host_since'], infer_datetime_format=True)\n",
                "\n",
                "# remove percent symbol and make float type\n",
                "hosts['host_response_rate'] = hosts['host_response_rate'].str.replace('%', '')\n",
                "hosts['host_response_rate'] = hosts['host_response_rate'].astype('float')\n",
                "hosts['host_acceptance_rate'] = hosts['host_acceptance_rate'].str.replace('%','') \n",
                "hosts['host_acceptance_rate'] = hosts['host_acceptance_rate'].astype('float')\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Merge dataset with listings\n",
                "df = listings.merge(hosts, on=['host_id'], how = 'left')\n",
                "df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**File 3: reviews.csv**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inspect dataset\n",
                "\n",
                "display(reviews.shape)\n",
                "display(reviews.info())\n",
                "display(reviews.describe())\n",
                "\n",
                "reviews.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check id column for uniqueness since this should be a primary key for identifies each row.\n",
                "reviews['id'].is_unique\n",
                "reviews[reviews['id'].duplicated()]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We see that something has gone wrong with the data import and some of the id columns have been scraped as scientific values.\n",
                "\n",
                "This is about 1/10th of our data, so given that we wont be looking at reviews individually but as a whole we will leave these."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Some fixes that we can do include:**\n",
                "\n",
                "remove duplicate row.\n",
                "\n",
                "* Remove empty rows from import error\n",
                "* change columns review_id and listing_id to a int instead of float.\n",
                "* change date to datetime type"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "reviews.dropna(inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "# change columns to appropriate data types\n",
                "reviews[['reviewer_id','listing_id']] = reviews[['reviewer_id','listing_id']].astype('int')\n",
                "reviews['date'] = pd.to_datetime(reviews['date'], infer_datetime_format=True) \n",
                "reviews.info()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "Unfortunately we dont get to see the actual rating of the reviews, we can focus perhaps on the contents of the reviews.\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **4. Analysis**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 1:**\n",
                "\n",
                "**As of 2022, what is the most common suburb to find an Airbnb with a rating over 4?**\n",
                "\n",
                "We will explore the top 10 neighboorhood with the most available Airbnb's . Using a barchart to clearly show the difference of the top 10 \n",
                "\n",
                "and a map to visualize the locations.\n",
                "-"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# First we can filter out any listings with less than a 4 star rating\n",
                "over_4_stars = df[df['review_scores_rating'] \u003e 4]\n",
                "\n",
                "# Group by neighbourhood \n",
                "top_neighbourhoods = over_4_stars.groupby('neighbourhood').size()\n",
                "\n",
                "# Sort the values\n",
                "top_neighbourhoods = top_neighbourhoods.nlargest(10).sort_values()\n",
                "\n",
                "# Show on a horizontal bar graph\n",
                "# A verticle bar graph gets harder to read with more values on the x axis so we go with horizontal\n",
                "top_neighbourhoods.plot.barh(title = 'Top Airbnb neighbourhoods with 4+ star ratings', color = '#FF5A5F')\n",
                "plt.xlabel('Count')\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer**\n",
                "\n",
                "Looks like Melbourne CBD will be your best bet at finding an Airbnb with a rating of over 4.\n",
                "\n",
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 2**\n",
                "\n",
                "**As of 2022, what suburbs have the most bookings?**\n",
                "\n",
                "Using the availability_x columns we can find out which areas have the most actual bookings. We explore the percentage of all available bookings in the area."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtract days available from 365 for a clear int of how many days the listing has been booked \n",
                "listings['days_booked'] = 365 - listings['availability_365']\n",
                "\n",
                "# Sum the days booked for each neighbourhood\n",
                "bookings_per_neighbourhood = listings.groupby('neighbourhood')['days_booked'].sum()\n",
                "\n",
                "# sort the values and create a bar chart\n",
                "bookings_per_neighbourhood = bookings_per_neighbourhood.nlargest(10).sort_values()\n",
                "bookings_per_neighbourhood.plot.barh(title = 'Days Booked', color = '#FF5A5F')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As expected the areas with the most listings have the most bookings. We will dig further into this by finding the percentage of bookings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create column for calculation reference of total availability\n",
                "listings['year_days'] = 365\n",
                "\n",
                "# Create a new df to work out percentage\n",
                "bookings_perc = listings[['neighbourhood','days_booked', 'year_days']].copy()\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Groupby neighbourhood and sum \n",
                "bookings_perc = bookings_perc.groupby('neighbourhood').sum()\n",
                "\n",
                "# We can now divide the booked days by the total days to get a percentage\n",
                "bookings_perc['total_booked_percent_365'] = round(bookings_perc['days_booked']/ bookings_perc['year_days'],2) * 100\n",
                "\n",
                "# Sort values then visualize with bar chart\n",
                "bookings_perc = bookings_perc['total_booked_percent_365'].nlargest(10).sort_values()\n",
                "bookings_perc.plot.barh(title = '% of availability booked', color = '#FF5A5F')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer**\n",
                "\n",
                "Now we get a much more interesting result.\n",
                "\n",
                "As we can see Yarra has the highest bookings percentage. \n",
                "Maybe if you were thinking of purchasing an investment property to list on Airbnb, you could pick one of the top areas as there is not an over supply.\n",
                "\n",
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 3**\n",
                "\n",
                "What is the distribution of prices for different suburbs?\n",
                "\n",
                "When thinking of either buying a property to host or looking to stay at an Airbnb, we want to know if the price of these listings are appropriate.\n",
                "\n",
                "We can compare them to the median/mean but it may be better to get an understanding of the range of values. \n",
                "\n",
                "we will create bar plots for each of the neighborhoods to visualize the distribution and compare easily to other areas.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extra cleaning that we missing earlier to prepare the price column\n",
                "listings['price'] = listings['price'].str.replace('$','')\n",
                "listings['price'] = listings['price'].str.replace(',','')\n",
                "listings['price'] = listings['price'].astype('float')\n",
                "\n",
                "# plot the prices \n",
                "sns.boxplot(data=listings, x ='price', y='neighbourhood')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As we see the outlier makes it difficult to see any clear patterns amongst the areas.\n",
                "\n",
                "Next we will remove the outliers to clearly see the bulk of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plot prices excluding the outliers.\n",
                "sns.boxplot(data=listings, x ='price', y='neighbourhood',showfliers = False, color='#FF5A5F' )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crate a new df exluding lines that are higher than the 95th quantile\n",
                "# so colour gradient in visualization is clearer\n",
                "listings_outlier_removed = listings[listings['price'] \u003c listings['price'].quantile(.95)]\n",
                "\n",
                "# Plot the location of all listings and darker colours will represnt higher mean prices in that hexbin\n",
                "# Prices vary quite a bit so a more robust average is the median.\n",
                "ax1 = listings_outlier_removed.plot.hexbin(\n",
                "    x = 'longitude',\n",
                "    y = 'latitude',\n",
                "    C = 'price',\n",
                "    reduce_C_function = np.median,\n",
                "        gridsize = 50)\n",
                "\n",
                "# Plot a point representing Melbourne CBD for reference\n",
                "ax2 = plt.scatter(x=144.9631,y=-37.8136, color='red') \n",
                "\n",
                "# set limits so map is focused on melbourne\n",
                "ax1.set_xlim([144.4,145.7])\n",
                "ax1.set_ylim(-38.3,-37.4)\n",
                "ax1.set_facecolor('#E5E4E2')\n",
                "plt.savefig('plot1.png')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer**\n",
                "\n",
                "As we can see the distribution for most areas sits within the $80 to $200 mark with very little areas having listings over $400 per night.\n",
                "\n",
                "The further away you get from the CBD the average listing price for neighbourhoods will likely be higher.\n",
                "\n",
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 4**\n",
                "\n",
                "**Which hosts are the most popular? Why?**\n",
                "\n",
                "It would be good to have an understanding of what successfull hosts have in common so we can can replicate if we like.\n",
                "\n",
                "First we need to define popular/successfull.\n",
                "\n",
                "We will create a new column that calculates the earning potential of the listings. (days booked * price) \n",
                "\n",
                "We will take our top hosts and see if we can find anything in common."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create new earning potential column\n",
                "listings['earning_potential'] = listings['days_booked'] * listings['price']\n",
                "\n",
                "# group by hosts and sort\n",
                "top_hosts = listings.groupby(by='host_id')['earning_potential'].sum()\n",
                "top_hosts = top_hosts.sort_values(ascending=False)\n",
                "\n",
                "# Create 20 quantiles and we will grab the group in the 20th percentile (top 5%)\n",
                "cut_df = pd.qcut(top_hosts, 20, labels=range(1,21))\n",
                "cut_df = cut_df[cut_df==20]\n",
                "\n",
                "#find the actual details of our hosts.\n",
                "top_hosts = hosts[hosts['host_id'].isin(cut_df.index)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyse the hosts\n",
                "display(top_hosts['host_since'].median())\n",
                "display(top_hosts['host_response_rate'].value_counts())\n",
                "display(top_hosts['host_response_time'].value_counts())\n",
                "sns.boxplot(data=top_hosts, y='host_total_listings_count',showfliers=False, color='#FF5A5F')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
                "\n",
                "# Find how many of the hosts are verified\n",
                "verified = top_hosts.groupby('host_identity_verified').size()\n",
                "#change the index from just 'f' and 't' to False and True\n",
                "verified = verified.rename(index={'f':'False', 't':'True'})\n",
                "\n",
                "ax1.pie(verified, colors=['grey','#FF5A5F'], labels = verified.index, autopct='%1.1f%%')\n",
                "ax1.set_title('Host is verified')\n",
                "\n",
                "\n",
                "# Find how many of the hosts are verified\n",
                "superhost = top_hosts.groupby('host_is_superhost').size()\n",
                "#change the index from just 'f' and 't' to False and True\n",
                "superhost = superhost.rename(index = {'t':'True','f':'False'})\n",
                "\n",
                "ax2.pie(superhost, colors=['grey','#FF5A5F'], labels=superhost.index, autopct='%1.1f%%')\n",
                "ax2.set_title('Host is Superhost')\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Most the results are what we would expect to see.\n",
                "\n",
                "On average has been a host for a while (since 2015), quick and high response rates, verified and on average own mulitple lisitngs.\n",
                "\n",
                "The most interesting result would be that most of them are not considered Superhosts.\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "# find the average rating of all listings per host\n",
                "average_ratings = listings.groupby('host_id')['review_scores_rating'].mean()\n",
                "\n",
                "#add the hosts average rating to the host table and find the average of the top hosts\n",
                "top_hosts_avg = top_hosts.merge(average_ratings, on=['host_id'], how = 'left')\n",
                "round(top_hosts_avg['review_scores_rating'].median(),2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get the hosts that are not in the top hosts dataframe and find their average.\n",
                "not_top_hosts = average_ratings[~average_ratings.isin(top_hosts['host_id'])]\n",
                "round(not_top_hosts.median(),2)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Interestingly the median average though very small difference is actually higher for the hosts not with high earning potential.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a df of hosts not in the top_hosts df\n",
                "other_hosts = hosts[~hosts['host_id'].isin(top_hosts['host_id'])]\n",
                "# count how many are superhosts\n",
                "other_hosts_agg = other_hosts['host_is_superhost'].value_counts()\n",
                "# relable to t to True and f to False\n",
                "other_hosts_agg = other_hosts_agg.rename(index = {'t':'True','f':'False'})\n",
                "# Plot as a pie chart\n",
                "other_hosts_agg.plot.pie( autopct='%1.1f%%',colors=['grey','#FF5A5F'], labels=other_hosts_agg.index)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "top_hosts"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer**\n",
                "\n",
                "From this breif analysis we see that having the 'superhost' badge or higher ratings might not actually result in higher earning potential.\n",
                "\n",
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 5**\n",
                "\n",
                "**Does the number of reviews have an effect on the price/availability?**\n",
                "\n",
                "As we all know, everytime you buy a service or a product we are promted to leave a review and often offered some sort of reward as this is supposed to encourage new customers.\n",
                "\n",
                "We will have a look if listings with more reviews are often priced higher and have more bookings to find out if reviews do help.\n",
                "\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a scatter plot to see if we can identify any linear relationship \n",
                "#   between the price and number of reviews for each listings\n",
                "plt.scatter(data=listings, x='number_of_reviews', y='price',alpha=0.5, color='#FF5A5F')\n",
                "\n",
                "# limit the visual so we can easily see the bulk of the data\n",
                "plt.ylim([0, 800])\n",
                "plt.xlim([0,25])\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "# remove the outliers (any value greater than the 95th percentile price)\n",
                "listings_outliers_removed = listings[listings['price'] \u003c listings['price'].quantile(.95)]\n",
                "\n",
                "# remove the outliers (any value greater than the 95th percentile number of reviews)\n",
                "listings_outliers_removed = (listings_outliers_removed[listings_outliers_removed['number_of_reviews']\n",
                "                 \u003c listings_outliers_removed['number_of_reviews'].quantile(.95)])\n",
                "\n",
                "# create a hex plot to see the relationship along with the distribution of each variable\n",
                "sns.jointplot(data=listings_outliers_removed, x=\"number_of_reviews\", y=\"price\", kind=\"hex\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The plots dont immediately  show any interesting patterns so we will leave it there and assume that price of Airbnb's dont have any relationship with reviews.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plot the relationship between the availability and price\n",
                "plt.scatter(data=listings, x='days_booked', y='price',alpha=0.5, color='#FF5A5F')\n",
                "\n",
                "# once again limit the x and y axis to get a clearer look at a bulk of the data.\n",
                "plt.ylim([0, 1000])\n",
                "plt.xlim([0,365])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer**\n",
                "\n",
                "The plots dont immediately  show any interesting patterns so we will leave it there and assume that price of Airbnb's dont have any relationship with reviews.\n",
                "\n",
                "Again the plots dont immediately show any patterns, it is relativley straight, so we will assume that price of Airbnb's dont have any relationship with availabilty.\n",
                "\n",
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 6**\n",
                "\n",
                "**Most common amenities in higher cost Airbnb's that are not available in the lower cost Airbnb's**\n",
                "\n",
                "We can see maybe what type of amenities are viewed as more valuable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "# we will create 2 tables of even size, based on rating the top 50% rated listings and bottom 50%\n",
                "\n",
                "# create df of top 50% of listings\n",
                "above_fifty_percentile = listings[listings['review_scores_rating']\u003elistings['review_scores_rating'].quantile(.5)]\n",
                "# Only include columns we want\n",
                "above_fifty_percentile = above_fifty_percentile[['id','amenities']]\n",
                "\n",
                "# create df of bottom 50% of listings\n",
                "below_fifty_percentile = listings[listings['review_scores_rating']\u003clistings['review_scores_rating'].quantile(.5)]\n",
                "# Only include columns we want\n",
                "below_fifty_percentile = below_fifty_percentile[['id','amenities']]\n",
                "\n",
                "# Create a function that will transform our amenities column from a single string object to a list \n",
                "def string_to_list(series):\n",
                "    \"\"\" takes in a series and converts the string object from each row into a list\"\"\"\n",
                "    \n",
                "    # split string into list by commas ,\n",
                "    series = series.split(',')\n",
                "    # initiate a new list to store the new clean values\n",
                "    new_list = []\n",
                "    # iterate over each item in the amentites string and clean it then add it to our list\n",
                "    for item in series:\n",
                "        a = item.replace('[','')\n",
                "        a = a.replace(']', '')\n",
                "        a = a.replace('\"','')\n",
                "        new_list.append(a)\n",
                "    return new_list\n",
                "\n",
                "# apply our function to the amenities column\n",
                "above_fifty_percentile['amenities'] = above_fifty_percentile['amenities'].apply(lambda x: string_to_list(x))\n",
                "below_fifty_percentile['amenities'] = below_fifty_percentile['amenities'].apply(lambda x: string_to_list(x))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "# transform the df so now there is a row for each of the amenities for each id\n",
                "above_fifty_percentile = above_fifty_percentile.explode('amenities')\n",
                "below_fifty_percentile = below_fifty_percentile.explode('amenities')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count the occurance of each amenity and transpose so each row represts an amenity\n",
                "above_fifty_pivot = above_fifty_percentile.pivot_table(columns= 'amenities', aggfunc='count')\n",
                "above_fifty_pivot = above_fifty_pivot.transpose()\n",
                "\n",
                "# Count the occurance of each amenity and transpose so each row represts an amenity\n",
                "below_fifty_pivot = below_fifty_percentile.pivot_table(columns= 'amenities', aggfunc='count')\n",
                "below_fifty_pivot = below_fifty_pivot.transpose()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "above_fifty_pivot = above_fifty_pivot.sort_values(by='id', ascending=False).nlargest(n=20,columns='id')\n",
                "below_fifty_pivot = below_fifty_pivot.sort_values(by='id', ascending=False).nlargest(n=20,columns='id')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Above 50th percentile')\n",
                "print(above_fifty_pivot)\n",
                "\n",
                "print('\\n\\nBelow 50th percentile')\n",
                "print(below_fifty_pivot)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer**\n",
                "\n",
                "Overall, it doesnt seem to be any major differences in the top 20 amenities between the 2 groups.\n",
                "\n",
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 7**\n",
                "\n",
                "**From all the data sets, can we identifiy any correlatin that may be worth investigating?**\n",
                "\n",
                "We can see what factors will likely to affect each other.\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a correlation matrix for all the listings variables\n",
                "corr_listings = listings.corr()\n",
                "\n",
                "# plot the values in a heatmap to easily identify relationships\n",
                "plt.figure(figsize=(15,8))\n",
                "sns.heatmap(corr_listings, annot=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a correlation matrix for all the listings variables\n",
                "corr_hosts = hosts.corr()\n",
                "\n",
                "# plot the values in a heatmap to easily identify relationships\n",
                "plt.figure(figsize=(15,8))\n",
                "sns.heatmap(corr_hosts, annot=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": [
                "# the review table lacks numerical columns so we will create a \n",
                "# length column which will hold the length of the review\n",
                "reviews['length'] = reviews['comments'].apply(lambda x: len(x))\n",
                "\n",
                "#merge the reviews with the listing table to get the listing ratings\n",
                "reviews = reviews.merge(listings[['id', 'review_scores_rating']], left_on=['listing_id'],right_on=['id'], how='left')\n",
                "reviews = reviews[['listing_id','date','reviewer_id','comments','length', 'review_scores_rating']]\n",
                "\n",
                "# create a correlation matrix for all the listings variables\n",
                "corr_reviews = reviews.corr()\n",
                "\n",
                "# plot the values in a heatmap to easily identify relationships\n",
                "plt.figure(figsize=(15,8))\n",
                "sns.heatmap(corr_reviews, annot=True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer**\n",
                "\n",
                "In the listings df the noticable relationships are what we would expect. The bathrooms, bedrooms, beds, and accomadate columns are all positively correlated. If the listings accomadates more people it would need more beds, bedrooms and bathrooms to do this.\n",
                "\n",
                "In the hosts df, the acceptance and response rate are the most related. Hosts with higher response rates often accept more.\n",
                "\n",
                "The reviews df doesnt have many strong relationships, the strongest being the length of the review and the reviewer_id. The reviewer_id is not a an actual value represnting anything so this doesnt really tell us anything.\n",
                "\n",
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**5. Conclusion**\n",
                "\n",
                "We can conclude by stating the the difference in price amongst listings may be heavily dependant on the area, and possibly lightly affected by other factors such as ratings.\n",
                "\n",
                "We found that the area with the most listing was with rating over 4 was Melbourne CBD with over 2000 listings. Doubling the amount of listings in the next area, Port Phillip.\n",
                "\n",
                "The ranking of amount of days booked per area is relatively the same when looking at absolute values but when converting the values to percentages, Melbourne falls down to the 5th position and Yarra takes the top spot at approximately 80% booked. This can be used to indicate the supply and demand.\n",
                "\n",
                "When looking at the pricing of listings for each neighborhood, the distribution was similar for each, 50% of the listings being between $80 - $200. \n",
                "Bayside had the widest distribution, and Yarra Ranges having the highest median.\n",
                "When plotting the locations and median prices we saw that areas further from the CBD were likely to have higher median prices.\n",
                "\n",
                "When investigating the data we had on the hosts we hoped to identify what factors may result in a more successfull host. successfull hosts being measured by earning potential (days booked * price) and taking the top 5% of hosts. We didnt find any noticable differences between the top 5% and the rest of the hosts.\n",
                "\n",
                "When looking at the effectiveness of listings having reviews, the number of reviews for a listing didnt not show any relationship with price niether did it show any relationship with availability.\n",
                "\n",
                "Looking at the amenities offered for each listing, the top 50% rated listings didnt seem to have any different offerings compared to the lower 50%.\n",
                "\n",
                "There were several subtle correlations amongst the columns, perhaps could be explored more but no correlations stood out.\n",
                "\n",
                "Overall, much of the analysis showed that listings did not clearly show any relationship with any of the explored variables, if you wanted to get an idea for the price of the property you most accurate guess would be based of the location.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**6. Recommendations**\n",
                "\n",
                "Many of the factors explored show no indication to pricing or availabilty. In the future to better understand the data we could:\n",
                "\n",
                "\n",
                "* Include all the data, this may have skewed the results by chance.\n",
                "* Conduct some natural language processing on the review comments to get an idea of common terms and sentitment for listings. \n",
                "* group ammenities and remove the standard ones to get an idea of the more unique ammenties offered for different rated listings.\n",
                "* Conduct analysis on a focused area to get a better idea of what factors outside of location affect pricing."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**7. References**\n",
                "\n",
                "Pandas Developers (2022). *Pandas Documentation*. Available at: https://pandas.pydata.org/docs/index.html [Accessed 12 Nov. 2022]\n",
                "\n",
                "Matplotlib Developers (2020) *Matplotlib 3.1.2 Documentation* Available at: https://matplotlib.org/3.1.1/contents.html [Accessed 12 Nov. 2022]\n",
                "\n",
                "Ajitesh, Kumar (2022). *Correlation Concepts, Matrix \u0026 Heatmap using Seaborn.* Available at: https://vitalflux.com/correlation-heatmap-with-seaborn-pandas/ [Accessed 19 Nov. 2022]\n",
                "\n",
                "Landup, David (2021) *How to set axis range* Available at: https://stackabuse.com/how-to-set-axis-range-xlim-ylim-in-matplotlib/ [Accessed 23 Nov. 2022]\n",
                "\n",
                "MachineLearningPlus (2021) *Pandas Series to List* Available at: https://www.machinelearningplus.com/pandas/pandas-series-to-list/#:~:text=Pandas%20series%20can%20be%20converted,and%20perform%20the%20required%20operations. [Accessed 25 Nov. 2022]\n",
                "\n",
                "Seaborn Devlopers (2022). *seaborn.jointplot* Available at: https://seaborn.pydata.org/generated/seaborn.jointplot.html [Accessed 25 Nov. 2022]\n",
                ""
            ]
        }
    ]
}
